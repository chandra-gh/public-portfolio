{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Arabian Nights\\nIn the chronicles of the ancien'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Arabian nights\n",
    "file = 'arabian-nights.txt'\n",
    "corpus = None\n",
    "with open(file, 'r') as f:\n",
    "    corpus = f.read()\n",
    "\n",
    "corpus[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[1], [1, 4049], [10], [10, 1], [10, 1, 4050]], [4049, 1853, 1, 4050, 4])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the content\n",
    "tokenizer = keras.preprocessing.text.Tokenizer()\n",
    "seq_len = 15\n",
    "\n",
    "def generate_training_data(corpus, seq_len):\n",
    "    # Populate the tokenizer vocabulary\n",
    "    tokenizer.fit_on_texts([corpus])\n",
    "    \n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    \n",
    "    for line in corpus.split('\\n')[:1000]:\n",
    "        if len(line.strip()) == 0:\n",
    "            continue\n",
    "        tokens = tokenizer.texts_to_sequences([line])[0]\n",
    "        if len(tokens) == 0:\n",
    "            continue\n",
    "        for i in range(1, len(tokens)):\n",
    "            if i < seq_len:\n",
    "                seqX = tokens[:i]\n",
    "            else:\n",
    "                seqX = tokens[i-seq_len+1:i]\n",
    "            dataX.append(seqX)\n",
    "            dataY.append(tokens[i])\n",
    "    return dataX, dataY\n",
    "\n",
    "dataX, dataY = generate_training_data(corpus, seq_len)\n",
    "dataX[:5], dataY[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23366, 1)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pad the input sequences\n",
    "paddedX = keras.preprocessing.sequence.pad_sequences(dataX, maxlen=seq_len)\n",
    "\n",
    "X = np.array(paddedX)\n",
    "Y = np.array(dataY).reshape((len(dataY), 1))\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 15, 20)            127060    \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 256)               283648    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 6353)              1632721   \n",
      "=================================================================\n",
      "Total params: 2,043,429\n",
      "Trainable params: 2,043,429\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "def create_model(vocab_size, seq_len):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Embedding(vocab_size, 20, input_length=seq_len))\n",
    "    # LSTM\n",
    "    model.add(keras.layers.LSTM(256))\n",
    "    # Regularization layer\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    # Dense softmax\n",
    "    model.add(keras.layers.Dense(vocab_size, activation=\"softmax\"))\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model(len(tokenizer.word_index)+1, seq_len)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "731/731 [==============================] - 47s 64ms/step - loss: 0.7660 - accuracy: 0.8138\n",
      "Epoch 2/20\n",
      "731/731 [==============================] - 47s 64ms/step - loss: 0.7207 - accuracy: 0.8262\n",
      "Epoch 3/20\n",
      "731/731 [==============================] - 47s 65ms/step - loss: 0.6956 - accuracy: 0.8310\n",
      "Epoch 4/20\n",
      "731/731 [==============================] - 45s 61ms/step - loss: 0.6538 - accuracy: 0.8421\n",
      "Epoch 5/20\n",
      "731/731 [==============================] - 48s 66ms/step - loss: 0.6358 - accuracy: 0.8422\n",
      "Epoch 6/20\n",
      "731/731 [==============================] - 48s 65ms/step - loss: 0.6071 - accuracy: 0.8507\n",
      "Epoch 7/20\n",
      "731/731 [==============================] - 42s 58ms/step - loss: 0.5783 - accuracy: 0.8591\n",
      "Epoch 8/20\n",
      "731/731 [==============================] - 42s 57ms/step - loss: 0.5622 - accuracy: 0.8596\n",
      "Epoch 9/20\n",
      "731/731 [==============================] - 43s 59ms/step - loss: 0.5495 - accuracy: 0.8638\n",
      "Epoch 10/20\n",
      "731/731 [==============================] - 39s 53ms/step - loss: 0.5374 - accuracy: 0.8666\n",
      "Epoch 11/20\n",
      "731/731 [==============================] - 39s 53ms/step - loss: 0.5138 - accuracy: 0.8696\n",
      "Epoch 12/20\n",
      "731/731 [==============================] - 39s 53ms/step - loss: 0.5074 - accuracy: 0.8707\n",
      "Epoch 13/20\n",
      "731/731 [==============================] - 39s 53ms/step - loss: 0.4892 - accuracy: 0.8771\n",
      "Epoch 14/20\n",
      "731/731 [==============================] - 40s 55ms/step - loss: 0.4775 - accuracy: 0.8791\n",
      "Epoch 15/20\n",
      "731/731 [==============================] - 40s 55ms/step - loss: 0.4665 - accuracy: 0.8824\n",
      "Epoch 16/20\n",
      "731/731 [==============================] - 39s 54ms/step - loss: 0.4739 - accuracy: 0.8772\n",
      "Epoch 17/20\n",
      "731/731 [==============================] - 39s 54ms/step - loss: 0.4609 - accuracy: 0.8808\n",
      "Epoch 18/20\n",
      "731/731 [==============================] - 39s 54ms/step - loss: 0.4637 - accuracy: 0.8794\n",
      "Epoch 19/20\n",
      "731/731 [==============================] - 39s 54ms/step - loss: 0.4311 - accuracy: 0.8892\n",
      "Epoch 20/20\n",
      "731/731 [==============================] - 40s 55ms/step - loss: 0.4154 - accuracy: 0.8939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8d76ae9a50>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model (the model for trained for roughly 80 epochs)\n",
    "model.fit(X, Y, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the magic carpet bought a house and a great city which was filled by the young lady keeping a little came into the centre of my daughter and was bounded by the room of him that he was four overcome at a room of which she said to take them for your head he is one and what the merchant who is do to know your life to tell me but the vizir had a most beautiful jewels came who came here with the deliberate intention of causing his life to put his the genius life that he had all the stones found a well and']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_text = 'the magic carpet bought a house'\n",
    "gen_tokens = tokenizer.texts_to_sequences([seed_text])\n",
    "for i in range(100):\n",
    "    if len(gen_tokens[0]) > seq_len:\n",
    "        seed_tokens = np.array([gen_tokens[0][-seq_len:]])\n",
    "    else:\n",
    "        seed_tokens = keras.preprocessing.sequence.pad_sequences(gen_tokens, maxlen=seq_len)\n",
    "    preds = model.predict(seed_tokens)\n",
    "    index = np.argmax(preds)\n",
    "    gen_tokens[0].append(index)\n",
    "tokenizer.sequences_to_texts(gen_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
