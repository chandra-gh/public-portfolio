{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten Number Classifier\n",
    "\n",
    "Simple model to classify handwritten numbers.\n",
    "\n",
    "Model classifies 28x28 grayscale images from MNIST data set into one of the 10 digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the input data\n",
    "(x_train_org, y_train_org), (x_test_org, y_test_org) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train_org\n",
    "y_train = y_train_org\n",
    "x_test = x_test_org\n",
    "y_test = y_test_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data\n",
      "-------------\n",
      "Training data (60000, 28, 28)\n",
      "Training labels (60000,)\n",
      "Test data (10000, 28, 28)\n",
      "Test labels (10000,)\n",
      "\n",
      "Sample labels [5 0 4 1 9]\n",
      "\n",
      "Train label frequencies\n",
      "5: 5421\n",
      "0: 5923\n",
      "4: 5842\n",
      "1: 6742\n",
      "9: 5949\n",
      "2: 5958\n",
      "3: 6131\n",
      "6: 5918\n",
      "7: 6265\n",
      "8: 5851\n",
      "\n",
      "Sample Image\n",
      "------------\n",
      "Expected label 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets take a peek at the data.\n",
    "print('Shape of data')\n",
    "print('-------------')\n",
    "print('Training data', x_train_org.shape)\n",
    "print('Training labels', y_train_org.shape)\n",
    "print('Test data', x_test_org.shape)\n",
    "print('Test labels', y_test_org.shape)\n",
    "print()\n",
    "print('Sample labels', y_train_org[:5])\n",
    "print()\n",
    "\n",
    "# Frequency of Y labels.\n",
    "vals, _, counts = tf.unique_with_counts(y_train_org)\n",
    "print('Train label frequencies')\n",
    "for i in range(len(vals)):\n",
    "    print(f'{vals[i]}: {counts[i]}')\n",
    "print()\n",
    "\n",
    "# Sample image\n",
    "index = 0\n",
    "print('Sample Image')\n",
    "print('------------')\n",
    "plt.imshow(x_train_org[index], cmap='gray')\n",
    "print('Expected label', y_train_org[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "* We have 60,000 28x28 grayscale images. Images are white on black background.\n",
    "* Y labels are not one-hot encoded.\n",
    "* We have 10,000 test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling_13 (Rescaling)     (None, 28, 28)            0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(28, 28)),\n",
    "    # Normalize grayscale values.\n",
    "    layers.experimental.preprocessing.Rescaling(1.0/255.),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Use sparse_categorical_crossentropy instead of categorical_crossentropy because Y-labels are not one-hot encoded.\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2645 - accuracy: 0.9247\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1175 - accuracy: 0.9646\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0807 - accuracy: 0.9754\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0592 - accuracy: 0.9816\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0461 - accuracy: 0.9863: 0s - loss: 0.0463 \n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0362 - accuracy: 0.9888\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0302 - accuracy: 0.9906\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0224 - accuracy: 0.9931\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0200 - accuracy: 0.9936\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0163 - accuracy: 0.9946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff04923c610>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0854 - accuracy: 0.9784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08541655540466309, 0.9783999919891357]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on the test set.\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.7, 0.0, 0.1, 0.0, 0.4, 0.1, 0.1, 0.0, 0.3, 0.3\n",
      "0.0, 99.1, 0.2, 0.3, 0.0, 0.1, 0.2, 0.1, 0.1, 0.0\n",
      "0.7, 0.3, 95.8, 0.8, 1.1, 0.0, 0.1, 0.3, 1.0, 0.0\n",
      "0.0, 0.0, 0.0, 98.1, 0.2, 0.6, 0.0, 0.1, 0.5, 0.5\n",
      "0.1, 0.0, 0.0, 0.1, 99.3, 0.0, 0.1, 0.0, 0.0, 0.4\n",
      "0.2, 0.0, 0.0, 0.7, 0.2, 97.4, 0.8, 0.0, 0.6, 0.1\n",
      "0.6, 0.3, 0.1, 0.1, 0.8, 0.3, 97.4, 0.0, 0.3, 0.0\n",
      "0.0, 0.6, 0.8, 0.3, 0.5, 0.0, 0.0, 96.7, 0.4, 0.8\n",
      "0.6, 0.0, 0.2, 0.3, 0.3, 0.3, 0.0, 0.1, 97.8, 0.3\n",
      "0.0, 0.2, 0.0, 0.1, 1.0, 0.5, 0.1, 0.0, 0.2, 97.9\n"
     ]
    }
   ],
   "source": [
    "# Error analysis\n",
    "results = np.zeros((10, 10), dtype='int32')\n",
    "preds = model.predict(x_test)\n",
    "for index in range(preds.shape[0]):\n",
    "    expected = y_test[index]\n",
    "    predicted = np.argmax(preds[index])\n",
    "    results[expected][predicted] += 1\n",
    "    \n",
    "for index in range(10):\n",
    "    row_total = np.sum(results[index])\n",
    "    row_pct = results[index]/row_total*100.\n",
    "    vals = []\n",
    "    for col in range(10):\n",
    "        vals.append(f'{row_pct[col]:.1f}')\n",
    "    print(\", \".join(vals))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Expected: 9\n",
      "    Predicted: 9\n",
      "    Probability: 1.00\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the model.\n",
    "index = 9\n",
    "x_in = x_test[index]\n",
    "plt.imshow(x_in, cmap='gray')\n",
    "preds = model.predict(np.array([x_in]))[0]\n",
    "pred_val = np.argmax(preds)\n",
    "print(f\"\"\"\n",
    "    Expected: {y_test[index]}\n",
    "    Predicted: {pred_val}\n",
    "    Probability: {preds[pred_val]:.2f}\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This is a very simple model to illustrate Keras and Deep Learning. It will not work as well in the real world for couple of reasons:\n",
    "* Numbers may not be centered in the image or could be smaller relative to the image. \n",
    "* Background noise can be varied - lines, spots.\n",
    "\n",
    "For the simple purpose of illustrating building a deep learning model in Keras, I think it serves well.\n",
    "\n",
    "Next lets deploy this model and see how it does with recognizing real handwritten numbers!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: hw-num-classifier-model/assets\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('hw-num-classifier-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
